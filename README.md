# llama-cpp-rx580
A sample Dockerfile that supports running LLMs with llama.cpp on the AMD RX580 GPU
